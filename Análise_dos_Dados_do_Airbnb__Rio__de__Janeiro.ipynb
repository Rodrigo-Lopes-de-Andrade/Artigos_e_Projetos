{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Análise_dos_Dados_do_Airbnb _Rio _de _Janeiro.ipynb",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMROMNVRGR02MI+aemEDkuW",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Rodrigo-Lopes-de-Andrade/Artigos_e_Projetos/blob/main/An%C3%A1lise_dos_Dados_do_Airbnb__Rio__de__Janeiro.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iy3WH7gT55wr"
      },
      "source": [
        "<p align=\"center\">\n",
        "    <a href=\"https://medium.com/rodrigo-lopesandrade\" alt=\"Contributors\">\n",
        "        <img src=\"https://img.shields.io/badge/Medium-RLA Data Science-magenta\" />\n",
        "    </a>\n",
        "<a href=\"https://linkedin.com/in/rodrigo-lopes-de-andrade-51753246\" alt=\"Contributors\">\n",
        "        <img src=\"https://img.shields.io/badge/Linkedin-Rodrigo Lopes de Andrade-cyan\" />\n",
        "    </a>\n",
        "<a href=\"https://github.com/Rodrigo-Lopes-de-Andrade\" alt=\"Contributors\">\n",
        "        <img src=\"https://img.shields.io/badge/GitHub-Rodrigo Lopes de Andrade-purple\" />\n",
        "    </a>\n",
        "<p align=\"center\">\n",
        "  <img src=\"https://raw.githubusercontent.com/Rodrigo-Lopes-de-Andrade/Portifolio_Rodrigo_Andrade/main/LOGORLA.JPG\" >\n",
        "</p>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uGhQ9hZ-6tgn"
      },
      "source": [
        "---\n",
        "\n",
        "# Análise dos Dados do Airbnb - Rio de Janeiro\n",
        "\n",
        "O [Airbnb](https://www.airbnb.com.br/) já é considerado como sendo a **maior empresa hoteleira da atualidade**.  o detalhe é que ele não possui nenhum hotel!\n",
        "\n",
        "Conectando pessoas que querem viajar (e se hospedar) com anfitriões que querem alugar seus imóveis de maneira prática, o Airbnb fornece uma plataforma inovadora para tornar essa hospedagem alternativa.\n",
        "\n",
        "No Brasil, o Airbnb divulgou que a plataforma gerou **um impacto econômico direto de R$ 7,7 bilhões em 2018**. Ainda segundo os cálculos da plataforma, em 245 países e regiões no mundo, é possível realizar mais de 60 mil conexões. \n",
        "\n",
        "No ranking do Índice de Conexões, **o Brasil ocupa o 11º lugar**. Anfitriões brasileiros já receberam viajantes de 207 países; e, brasileiros já foram para 203 nações diferentes.\n",
        "\n",
        "Em primeiro lugar está os Estados Unidos, que recebeu hóspedes de 242 países, e, no inverso, americanos estiveram em 235 nações.\n",
        "\n",
        "Uma das iniciativas do Airbnb é disponibilizar dados do site, para algumas das principais cidades do mundo. Por meio do portal [Inside Airbnb](http://insideairbnb.com/get-the-data.html), é possível baixar uma grande quantidade de dados para desenvolver projetos e soluções de *Data Science*.\n",
        "\n",
        "<center><img alt=\"Analisando Airbnb\" width=\"10%\" src=\"https://www.area360.com.au/wp-content/uploads/2017/09/airbnb-logo.jpg\"></center>\n",
        "\n",
        "**Neste *notebook*, iremos analisar os dados referentes à cidade do Rio de Janeiro, e ver quais insights podem ser extraídos a partir de dados brutos e realizar previsão dos preços.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l3vJ4V8N9u-M"
      },
      "source": [
        "## Obtenção dos Dados\n",
        "\n",
        "Todos os dados usados aqui foram obtidos a partir do site [Inside Airbnb](http://insideairbnb.com/get-the-data.html).\n",
        "\n",
        "Para esta análise exploratória inicial, será baixado apenas o seguinte arquivo:\n",
        "\n",
        "* `listings.csv` - *Summary information and metrics for listings in Rio de Janeiro (good for visualisations).*\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5fwrsdE69vyc"
      },
      "source": [
        "# importar os pacotes necessarios\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import plotly.express as px\n",
        "import plotly.graph_objs as go\n",
        "from plotly.subplots import make_subplots\n",
        "%matplotlib inline"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "28xs2AclHayQ"
      },
      "source": [
        "# Configurando o Background\n",
        "colors = ['#F06E5C','#5CF0C5','#F1F689','#F0B35C','#6EDEDE',\n",
        "          '#BB81D5','#D3D972','#EB83EE','#8B8CED','#F09674',\n",
        "          '#BCE374','#72C3E7','#C3A0EB','#E6809D','#A9BFCB']\n",
        "\n",
        "sns.palplot(sns.color_palette(colors))\n",
        "plt.title('Notebook Colors', size = 12)\n",
        "plt.axis('off')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1hqwE6oDCF-z"
      },
      "source": [
        "# importar o arquivo listings.csv para um DataFrame\n",
        "df = pd.read_csv(\"https://raw.githubusercontent.com/Rodrigo-Lopes-de-Andrade/Datasets/main/airbnb_rj_br.csv\")\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v8EuKv3aC6u6"
      },
      "source": [
        "## Análise Exploratória dos Dados\n",
        "Esta etapa tem por objetivo criar uma consciência situacional inicial e permitir um entendimento de como os dados estão estruturados."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EqqteRqcGU4O"
      },
      "source": [
        "### Dicionário das variáveis"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gxHxd38hHB6q"
      },
      "source": [
        "\n",
        "* `id` - número de id gerado para identificar o imóvel\n",
        "* `name` - nome da propriedade anunciada\n",
        "* `host_id` - número de id do proprietário (anfitrião) da propriedade\n",
        "* `host_name` - Nome do anfitrião\n",
        "* `neighbourhood_group` - esta coluna não contém nenhum valor válido\n",
        "* `neighbourhood` - nome do bairro\n",
        "* `latitude` - coordenada da latitude da propriedade\n",
        "* `longitude` - coordenada da longitude da propriedade\n",
        "* `room_type` - informa o tipo de quarto que é oferecido\n",
        "* `price` - preço para alugar o imóvel\n",
        "* `minimum_nights` - quantidade mínima de noites para reservar\n",
        "* `number_of_reviews` - número de reviews que a propriedade possui\n",
        "* `last_review` - data do último review\n",
        "* `reviews_per_month` - quantidade de reviews por mês\n",
        "* `calculated_host_listings_count` - quantidade de imóveis do mesmo anfitrião\n",
        "* `availability_365` - número de dias de disponibilidade dentro de 365 dias"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q813MBGwGaDQ"
      },
      "source": [
        "####Conhecendo a base de *dados*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wS9eQ8WkG6NW"
      },
      "source": [
        "# Crinado a função para resumir as principais estatisticas \n",
        "import scipy as sp\n",
        "from scipy import stats\n",
        "def resumetable(df):\n",
        "\n",
        "    print('Rows: {}'.format(df.shape[0]))\n",
        "    print('Columns: {}'.format(df.shape[1]))\n",
        "    summary = pd.DataFrame(df.dtypes,columns=['dtypes'])\n",
        "    summary = summary.reset_index()\n",
        "    summary['Name'] = summary['index']\n",
        "    summary = summary[['Name','dtypes']]\n",
        "    summary['Missing'] = df.isnull().sum().values    \n",
        "    summary['Uniques'] = df.nunique().values\n",
        "    summary['First Value'] = df.loc[0].values\n",
        "    summary['Second Value'] = df.loc[1].values\n",
        "    summary['Third Value'] = df.loc[2].values\n",
        "    summary['Duplicated Value'] = df.duplicated().sum()\n",
        "    \n",
        "    for name in summary['Name'].value_counts().index:\n",
        "        summary.loc[summary['Name'] == name, 'Entropy'] = round(stats.entropy(df[name].value_counts(normalize=True), base=2),2) \n",
        "\n",
        "    return summary"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jIIPd5bjH_B_"
      },
      "source": [
        "# Overview dos dados\n",
        "resumetable(df)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SOTXMzXDKVfQ"
      },
      "source": [
        "# Verificando as 20 primeiras linhas \n",
        "df.head(20)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HJdPyDvgLNlc"
      },
      "source": [
        "# Principais Estatísticas das Variáveis Numericas\n",
        "df.describe().T"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p3zN6hHCLQvr"
      },
      "source": [
        "# Valores Missing\n",
        "total = df.isnull().sum().sort_values(ascending=False)\n",
        "percent = (df.isnull().sum())/df.isnull().count().sort_values(ascending=False)\n",
        "missing_data = pd.concat([total, percent], axis=1, keys=['Total','Percent'], sort=False).sort_values('Total', ascending=False)\n",
        "missing_data.head(40)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "46oDQqCPOm8R"
      },
      "source": [
        "# Plotando Gráfico dos Valores Missing\n",
        "plt.figure(figsize=(8, 8))\n",
        "plt.title('Missing Values Per Feature')\n",
        "nans = df.isna().sum().sort_values(ascending=False).to_frame()\n",
        "sns.heatmap(nans,annot=True,fmt='d',cmap='vlag')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yliejcGaMZpm"
      },
      "source": [
        "# Trazendo Somente as colunas com valores missing \n",
        "def missing_values_table(dataframe, na_name=False):\n",
        "    na_columns = [col for col in dataframe.columns if dataframe[col].isnull().sum() > 0]\n",
        "    quantidade = dataframe[na_columns].isnull().sum().sort_values(ascending=False)\n",
        "    percentual = (dataframe[na_columns].isnull().sum() / dataframe.shape[0] * 100).sort_values(ascending=False)\n",
        "    missing_df = pd.concat([quantidade, np.round(percentual, 2)], axis=1, keys=['Total', 'Percent'])\n",
        "    print(missing_df, end=\"\\n\")\n",
        "    if na_name:\n",
        "        return na_columns\n",
        "missing_values_table(df)   "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4ErIwD0XeOxf"
      },
      "source": [
        "# Apagando as colunas 'host_name','name', 'neighbourhood_group'.\n",
        "df.drop(['host_name','name', 'neighbourhood_group'], axis=1, inplace=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9ODyfGwqSZYW"
      },
      "source": [
        "# Substituindo os valores missing pelo anterior \n",
        "df['last_review']= df['last_review'].fillna(method='ffill')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8t0oqWweVc1o"
      },
      "source": [
        "# Substituindo os valores missing pelo anterior \n",
        "df['reviews_per_month']= df['reviews_per_month'].fillna(method='ffill')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WtuiiDdnY4y9"
      },
      "source": [
        "# Valores Missing\n",
        "total = df.isnull().sum().sort_values(ascending=False)\n",
        "percent = (df.isnull().sum())/df.isnull().count().sort_values(ascending=False)\n",
        "missing_data = pd.concat([total, percent], axis=1, keys=['Total','Percent'], sort=False).sort_values('Total', ascending=False)\n",
        "missing_data.head(40)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-ApCg7tyUzS3"
      },
      "source": [
        "# Calcule a correlação  \n",
        "correlacoes = df.corr()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ScAAH3XeU2xD"
      },
      "source": [
        "# Usando o método heatmap do seaborn\n",
        "plt.figure(figsize=(16, 6))\n",
        "sns.heatmap(data=correlacoes, annot=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pGdEDNt0VPL7"
      },
      "source": [
        "# Função Para Correlação \n",
        "def pearson_corr(dataframe):\n",
        "    sns.set_style(\"white\")\n",
        "    matrix = np.triu(dataframe.corr(method=\"pearson\"))\n",
        "    f,ax=plt.subplots(figsize = (matrix.shape[0]*0.75,\n",
        "                                 matrix.shape[1]*0.75))\n",
        "    sns.heatmap(dataframe.corr(method=\"pearson\"),\n",
        "                annot= True,\n",
        "                fmt = \".2f\",\n",
        "                ax=ax,\n",
        "                vmin = -1,\n",
        "                vmax = 1,\n",
        "                mask = matrix,\n",
        "                cmap = \"coolwarm\",\n",
        "                linewidth = 0.4,\n",
        "                linecolor = \"white\",\n",
        "                annot_kws={\"size\": 12})\n",
        "    plt.xticks(rotation=80,size=14)\n",
        "    plt.yticks(rotation=0,size=14)\n",
        "    plt.title('Pearson Correlation Map', size = 14)\n",
        "    plt.show()\n",
        "    \n",
        "pearson_corr(df)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "onulnX-pdQCx"
      },
      "source": [
        "### Detecção de anomalias e valores extremos "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PJ1Tc89cdYbH"
      },
      "source": [
        "def CalcOutliers(df_num): \n",
        "    '''\n",
        "    Defina um valor numérico e ele irá calcular o número superior, inferior e total de outliers\n",
        "    Irá imprimir muitas estatísticas da característica numérica que você definiu na entrada\n",
        "    \n",
        "    '''\n",
        "    # calculando a média e o desvio padrão da matriz\n",
        "    data_mean, data_std = np.mean(df_num), np.std(df_num)\n",
        "\n",
        "   # definir a linha de corte para valores mais altos e mais baixos\n",
        "   # Você pode alterar este valor\n",
        "    cut = data_std * 3\n",
        "\n",
        "    #Calculando os valores de corte superior e inferior\n",
        "    lower, upper = data_mean - cut, data_mean + cut\n",
        "\n",
        "    # criando uma matriz de valores outlier inferior, superior e total\n",
        "    outliers_lower = [x for x in df_num if x < lower]\n",
        "    outliers_higher = [x for x in df_num if x > upper]\n",
        "    outliers_total = [x for x in df_num if x < lower or x > upper]\n",
        "\n",
        "    # array sem valores atípicos\n",
        "    outliers_removed = [x for x in df_num if x > lower and x < upper]\n",
        "    \n",
        "    print('Identified lowest outliers: %d' % len(outliers_lower)) # imprimindo o número total de valores no corte inferior de outliers\n",
        "    print('Identified upper outliers: %d' % len(outliers_higher)) # imprimindo o número total de valores no corte superior de outliers\n",
        "    print('Identified outliers: %d' % len(outliers_total)) # imprimindo número total de valores atípicos de ambos os lados\n",
        "    print('Non-outlier observations: %d' % len(outliers_removed)) # imprimindo o número total de valores não atípicos\n",
        "    print(\"Total percentual of Outliers: \", round((len(outliers_total) / len(outliers_removed) )*100, 4)) # Percentual de outliers em pontos\n",
        "    \n",
        "    return\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FMJsVpu7fUSq"
      },
      "source": [
        "CalcOutliers(df['price'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CJ3L7If-fyQ5"
      },
      "source": [
        "CalcOutliers(df['minimum_nights'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EravNXPKXDBw"
      },
      "source": [
        "# remover os *outliers* em um novo DataFrame\n",
        "df.drop(df[df.price > 1000].index, axis=0, inplace=True)\n",
        "df.drop(df[df.minimum_nights > 30].index, axis=0, inplace=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zb-iPRoqbjHv"
      },
      "source": [
        "data = go.Box(y=df['price'],name = 'Price',marker_color=\"#5CF0C5\")\n",
        "layout = go.Layout(title={'text': \"Price\",'y':0.9,'x':0.5,'xanchor': 'center',\n",
        "        'yanchor': 'top'}, width = 450, height=450)\n",
        "fig = go.Figure(data = data, layout=layout)\n",
        "fig.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yryqxq3kio7K"
      },
      "source": [
        "data = go.Box(y=df['minimum_nights'],name = 'minimum_nights',marker_color=\"#5CF0C5\")\n",
        "layout = go.Layout(title={'text': \"Minimum_nights\",'y':0.9,'x':0.5,'xanchor': 'center',\n",
        "        'yanchor': 'top'}, width = 450, height=450)\n",
        "fig = go.Figure(data = data, layout=layout)\n",
        "fig.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NmehV8oQJvdD"
      },
      "source": [
        "import plotly.express as px\n",
        "fig = px.box(df, x=\"room_type\", y=\"price\", points=\"all\",\n",
        "             color=\"room_type\", title=\"Box plot Room_Tip x Price\",)\n",
        "fig.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EPKcXhHiYldW"
      },
      "source": [
        "## insights"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ps3BhA-NY_FS"
      },
      "source": [
        "### **Qual o tipo de imóvel mais alugado no Airbnb?**\n",
        "\n",
        "A coluna da variável `room_type` indica o tipo de locação que está anunciada no Airbnb. Se você já alugou no site, sabe que existem opções de apartamentos/casas inteiras, apenas o aluguel de um quarto ou mesmo dividir o quarto com outras pessoas.\n",
        "\n",
        "Vamos contar a quantidade de ocorrências de cada tipo de aluguel, usando o método `value_counts()`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RXOs_SjMZB7A"
      },
      "source": [
        "# mostrar a quantidade de cada tipo de imóvel disponível\n",
        "df.room_type.value_counts()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pn-_GCcIZaGi"
      },
      "source": [
        "# mostrar a porcentagem de cada tipo de imóvel disponível\n",
        "df.room_type.value_counts() / df.shape[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "upg7Fa32zC0b"
      },
      "source": [
        "fig = make_subplots(rows=1,cols=2,\n",
        "                    subplot_titles=('Quantidade',\n",
        "                                    'Porcentagem'),\n",
        "                    specs=[[{\"type\": \"xy\"},\n",
        "                            {'type':'domain'}]])\n",
        "\n",
        "fig.add_trace(go.Bar( y = df['room_type'].value_counts().values.tolist(), \n",
        "                      x = df['room_type'].value_counts().index, \n",
        "                      text=df['room_type'].value_counts().values.tolist(),\n",
        "                      textfont=dict(size=15),\n",
        "                      name = 'porcentagem de cada tipo de imóvel disponível',\n",
        "                      textposition = 'auto',\n",
        "                      showlegend=False,\n",
        "                      marker=dict(color = colors,\n",
        "                                  line=dict(color='white',\n",
        "                                            width=1.5))),\n",
        "              row = 1, col = 1)\n",
        "\n",
        "fig.add_trace(go.Pie(labels=df['room_type'].value_counts().keys(),\n",
        "                     values=df['room_type'].value_counts().values,\n",
        "                     textfont = dict(size = 16),\n",
        "                     textposition='auto',\n",
        "                     showlegend = False,\n",
        "                     name = 'porcentagem de cada tipo de imóvel disponível',\n",
        "                     marker=dict(colors = colors)),\n",
        "              row = 1, col = 2)\n",
        "\n",
        "fig.update_layout(title={'text': 'Porcentagem de cada tipo de imóvel disponível',\n",
        "                         'y':0.9,\n",
        "                         'x':0.5,\n",
        "                         'xanchor': 'center',\n",
        "                         'yanchor': 'top'},\n",
        "                  template='plotly_white')\n",
        "\n",
        "fig.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rBumV7Q0ZsDu"
      },
      "source": [
        "### **Qual a localidade mais cara do Rio?**\n",
        "\n",
        "Uma maneira de se verificar uma variável em função da outra é usando `groupby()`. No caso, queremos comparar os bairros (*neighbourhoods*) a partir do preço de locação."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "im4OErmEZvjn"
      },
      "source": [
        "df.groupby(['neighbourhood']).price.mean().sort_values(ascending=False)[:10]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "raDRdSF_w1Ag"
      },
      "source": [
        "top10_horsepower = df.groupby(['neighbourhood']).agg({'price': 'mean'}). \\\n",
        "sort_values('price', ascending = False)[0:10].reset_index()\n",
        "\n",
        "data = go.Bar(x = top10_horsepower['neighbourhood'],\n",
        "              y = top10_horsepower['price'],\n",
        "              text =round(top10_horsepower['price'],2),\n",
        "              textposition= 'auto',\n",
        "              marker = dict(color = colors,\n",
        "                            line_color = colors,\n",
        "                            line_width = 1))\n",
        "\n",
        "layout = go.Layout(title= dict(text = 'TOP 10 DE PREÇO POR LOCALIDADE',\n",
        "                              x = 0.5,\n",
        "                              y = 0.9,\n",
        "                              xanchor = 'center',\n",
        "                              yanchor = 'top'),\n",
        "                   xaxis = dict(title='Localidade'),\n",
        "                   yaxis =dict(title='Preço Médio'),\n",
        "                   template='plotly_white')\n",
        "\n",
        "fig=go.Figure(data=data, layout=layout)\n",
        "fig.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-wtfjAY683XO"
      },
      "source": [
        "fig = px.scatter_mapbox(df, lat=\"latitude\", lon=\"longitude\", color=\"room_type\", size=\"price\",\n",
        "                 size_max=15, zoom=10, \n",
        "                  mapbox_style=\"carto-positron\")\n",
        "fig.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l4AxcftXkVsd"
      },
      "source": [
        "## Pré-Processamento"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S8IBDeLIkj_H"
      },
      "source": [
        "df.dtypes"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8iP5XZDikeAK"
      },
      "source": [
        "# Variaveis Categoricas\n",
        "categorical_features = df.select_dtypes(include=['object'])\n",
        "print('Categorical features: {}'.format(categorical_features.shape))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "82qSYuUgk63f"
      },
      "source": [
        "# Criando as dumies para as variáveis categoricas\n",
        "categorical_features_one_hot = pd.get_dummies(categorical_features)\n",
        "categorical_features_one_hot.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7A7bcCCBlV5I"
      },
      "source": [
        "df['reviews_per_month'] = df['reviews_per_month'].fillna(0)\n",
        "df.drop(['id','host_id'], axis=1, inplace=True)\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qm4oyQ8Wl40C"
      },
      "source": [
        "numerical_features =  df.select_dtypes(exclude=['object'])\n",
        "y = numerical_features.price\n",
        "numerical_features = numerical_features.drop(['price'], axis=1)\n",
        "print('Numerical features: {}'.format(numerical_features.shape))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rf1CB3CnnMJQ"
      },
      "source": [
        "X = np.concatenate((numerical_features, categorical_features_one_hot), axis=1)\n",
        "X_df = pd.concat([numerical_features, categorical_features_one_hot], axis=1)\n",
        "print('Dimensions of the design matrix: {}'.format(X.shape))\n",
        "print('Dimension of the target vector: {}'.format(y.shape))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J8ad-kPcsEJv"
      },
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.decomposition import TruncatedSVD\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.linear_model import Ridge\n",
        "from sklearn.metrics import mean_squared_error,r2_score\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "Y = df.price\n",
        "X = X_df\n",
        "\n",
        "RF_pipe = Pipeline(steps =[  (\"RF\",RandomForestRegressor(random_state=42)) ])\n",
        "LR_pipe = Pipeline(steps =[  (\"LR\",LinearRegression()) ])\n",
        "RIDGE_pipe = Pipeline(steps =[ (\"R\",Ridge()) ])\n",
        "\n",
        "\n",
        "RF_f1_cross_val_scores = np.sqrt(-1*cross_val_score(RF_pipe,X,Y,cv=5,scoring='neg_mean_squared_error'))\n",
        "LR_f1_cross_val_scores= np.sqrt(-1*cross_val_score(LR_pipe,X,Y,cv=5,scoring='neg_mean_squared_error'))\n",
        "RIDGE_f1_cross_val_scores= np.sqrt(-1*cross_val_score(RIDGE_pipe,X,Y,cv=5,scoring='neg_mean_squared_error'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mmZxfcUhtNBA"
      },
      "source": [
        "fig = make_subplots(rows=3, cols=1,shared_xaxes=True,subplot_titles=('Random Forest Cross Val Scores',\n",
        "                                                                     'Linear Regression Cross Val Scores',\n",
        "                                                                    'Ridge Regression Cross Val Scores'))\n",
        "\n",
        "fig.add_trace(\n",
        "    go.Scatter(x=np.arange(0,len(RF_f1_cross_val_scores)),y=RF_f1_cross_val_scores,name='Random Forest'),\n",
        "    row=1, col=1\n",
        ")\n",
        "fig.add_trace(\n",
        "    go.Scatter(x=np.arange(0,len(LR_f1_cross_val_scores)),y=LR_f1_cross_val_scores,name='Linear Regression'),\n",
        "    row=2, col=1\n",
        ")\n",
        "fig.add_trace(\n",
        "    go.Scatter(x=np.arange(0,len(RIDGE_f1_cross_val_scores)),y=RIDGE_f1_cross_val_scores,name='Ridge Regression'),\n",
        "    row=3, col=1\n",
        ")\n",
        "\n",
        "fig.update_layout(height=700, width=1000, title_text=\"Different Model 5 Fold Cross Validation\")\n",
        "fig.update_yaxes(title_text=\"RMSE\")\n",
        "fig.update_xaxes(title_text=\"Fold #\")\n",
        "\n",
        "fig.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d5eatWBLvhI7"
      },
      "source": [
        "def hyperparameter_estimators(X,Y,h_list):\n",
        "    r_s = []\n",
        "    for est in h_list:\n",
        "        model = Pipeline(steps =[  (\"RF\",RandomForestRegressor(random_state=42,n_estimators=est)) ])\n",
        "        model.fit(X,Y)\n",
        "        pred = model.predict(X)\n",
        "        r_s.append(r2_score(Y,pred))\n",
        "    return r_s"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6xbDJ7CZv_Yu"
      },
      "source": [
        "estimators_under_test = [10,50,100,300,500,700,850]\n",
        "rs = hyperparameter_estimators(X,Y,estimators_under_test)\n",
        "plt.plot(estimators_under_test,rs,'go--')\n",
        "plt.title(r'Choosing The Number of Estimators That Maximizes $R^2$ of Prediction',fontsize=17,fontweight='bold')\n",
        "plt.xticks(estimators_under_test)\n",
        "plt.ylabel(r'$R^2$ Value',fontsize=17,fontweight='bold')\n",
        "plt.xlabel(r'Number Of Estimators',fontsize=17,fontweight='bold')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y_p0l-cRwQYd"
      },
      "source": [
        "def hyperparameter_estimators(X,Y,h_list):\n",
        "    r_s = []\n",
        "    for est in h_list:\n",
        "        model = Pipeline(steps =[  (\"RF\",RandomForestRegressor(random_state=42,n_estimators=500,max_leaf_nodes=est)) ])\n",
        "        model.fit(X,Y)\n",
        "        pred = model.predict(X)\n",
        "        r_s.append(r2_score(Y,pred))\n",
        "    return r_s\n",
        "\n",
        "nodes_under_test = [2,3,5,7,10,30,50]\n",
        "rs = hyperparameter_estimators(X,Y,nodes_under_test)\n",
        "plt.plot(nodes_under_test,rs,'ro--')\n",
        "plt.title(r'Choosing The Number of Leaf Nodes That Maximizes $R^2$ of Prediction',fontsize=17,fontweight='bold')\n",
        "plt.xticks(nodes_under_test)\n",
        "plt.ylabel(r'$R^2$ Value',fontsize=17,fontweight='bold')\n",
        "plt.xlabel(r'Number Of Leaf Nodes',fontsize=17,fontweight='bold')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0iXakJ_kwZzm"
      },
      "source": [
        "rf_pipe = Pipeline(steps =[  (\"RF\",RandomForestRegressor(random_state=42,n_estimators=500,max_leaf_nodes=50)) ])\n",
        "rf_pipe.fit(X,Y)\n",
        "predictions = rf_pipe.predict(X)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2xJovmgvwfVU"
      },
      "source": [
        "print('Total RMSE For Prediction On Entire Dataset : {}'.format(RMSE(Y,predictions)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RpPqA5I2wmr2"
      },
      "source": [
        "plt.title(r'Validating That There Is No Visable Heteroscedasticity',fontsize=17,fontweight='bold')\n",
        "sns.residplot(predictions,Y)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lBddsuvjwr7W"
      },
      "source": [
        "output = pd.DataFrame({'Prediction':predictions,'Actual':Y})\n",
        "output.to_csv('view_prediction.csv',index=False)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}